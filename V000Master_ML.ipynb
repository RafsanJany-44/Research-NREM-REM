{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2476218d89cf48dc90d8c6fe7baba21f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "ALL",
              "User Defined with Index Range",
              "User Defined with Individual Feature",
              "Model Free 1",
              "Model Free 2",
              "Model Free 3",
              "Model Based:KNN"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Feture Select:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_d02a8553413b492aaf02a91d63999296",
            "style": "IPY_MODEL_c065a1509fa641a6bfa19c6dfd3bdc8c"
          }
        },
        "d02a8553413b492aaf02a91d63999296": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c065a1509fa641a6bfa19c6dfd3bdc8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafsanJany-44/Research-NREM-REM/blob/main/V000Master_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zdFOS9nFlpsU"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J6ZJsYeU7XEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "dataset=pd.read_csv(\"https://raw.githubusercontent.com/RafsanJany-44/Research-NREM-REM/main/dataset/REM_NREM.csv\")\n",
        "\n",
        "\n",
        "target=\"Sleep_Stage\"\n",
        "\n",
        "classes = np.array(sorted(list(set(dataset[target]))))\n"
      ],
      "metadata": {
        "id": "M0AmIUwSmLfj"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "4YN_C8yxm1ho",
        "outputId": "16475c95-ef40-4ed0-8c85-11b524d80717"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Sleep_Stage  MeanP_Alpha_F4  MedianF_Alpha_F4  MeanF_Alpha_F4  \\\n",
              "0        NREM         0.00034          10.11512        17.85756   \n",
              "1        NREM         0.00035          10.73951        17.60780   \n",
              "2        NREM         0.00035           9.36585        17.60780   \n",
              "3        NREM         0.00050          10.36488        16.60878   \n",
              "4        NREM         0.00072           9.36585        15.98439   \n",
              "\n",
              "   Spectral Edge_Alpha_F4  PeakF_Alpha_F4  MeanP_Beta_F4  MedianF_Beta_F4  \\\n",
              "0                17.48293        10.24000        0.00047         17.73268   \n",
              "1                17.10829         9.11610        0.00048         16.85854   \n",
              "2                16.98341         9.24098        0.00042         17.35805   \n",
              "3                15.85951         7.99220        0.00053         15.48488   \n",
              "4                15.48488         7.99220        0.00067         15.11024   \n",
              "\n",
              "   MeanF_Beta_F4  Spectral Edge_Beta_F4  ...  MeanP_Delta_O2  \\\n",
              "0       25.35024               27.47317  ...         0.00112   \n",
              "1       25.22537               26.97366  ...         0.00070   \n",
              "2       26.09951               28.47220  ...         0.00077   \n",
              "3       24.10146               25.72488  ...         0.00130   \n",
              "4       22.22829               23.22732  ...         0.00123   \n",
              "\n",
              "   MedianF_Delta_O2  MeanF_Delta_O2  Spectral Edge_Delta_O2  PeakF_Delta_O2  \\\n",
              "0           0.74927         6.36878                 2.87220         0.62439   \n",
              "1           0.99902         6.86829                 3.62146         0.74927   \n",
              "2           1.49854         6.49366                 4.12098         0.74927   \n",
              "3           1.87317         6.11902                 3.74634         0.37463   \n",
              "4           1.49854         6.61854                 3.74634         0.74927   \n",
              "\n",
              "   MeanP_Gamma_O2  MedianF_Gamma_O2  MeanF_Gamma_O2  Spectral Edge_Gamma_O2  \\\n",
              "0        0.000076          32.71805        43.83220                49.95122   \n",
              "1        0.000072          32.09366        44.33171                49.95122   \n",
              "2        0.000069          33.09268        43.95707                49.95122   \n",
              "3        0.000070          31.59415        42.83317                49.95122   \n",
              "4        0.000060          29.47122        45.08098                49.95122   \n",
              "\n",
              "   PeakF_Gamma_O2  \n",
              "0        49.95122  \n",
              "1        49.95122  \n",
              "2        49.95122  \n",
              "3        49.95122  \n",
              "4        49.95122  \n",
              "\n",
              "[5 rows x 76 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f09497fc-aade-4282-92df-9dc6d87ad8d7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sleep_Stage</th>\n",
              "      <th>MeanP_Alpha_F4</th>\n",
              "      <th>MedianF_Alpha_F4</th>\n",
              "      <th>MeanF_Alpha_F4</th>\n",
              "      <th>Spectral Edge_Alpha_F4</th>\n",
              "      <th>PeakF_Alpha_F4</th>\n",
              "      <th>MeanP_Beta_F4</th>\n",
              "      <th>MedianF_Beta_F4</th>\n",
              "      <th>MeanF_Beta_F4</th>\n",
              "      <th>Spectral Edge_Beta_F4</th>\n",
              "      <th>...</th>\n",
              "      <th>MeanP_Delta_O2</th>\n",
              "      <th>MedianF_Delta_O2</th>\n",
              "      <th>MeanF_Delta_O2</th>\n",
              "      <th>Spectral Edge_Delta_O2</th>\n",
              "      <th>PeakF_Delta_O2</th>\n",
              "      <th>MeanP_Gamma_O2</th>\n",
              "      <th>MedianF_Gamma_O2</th>\n",
              "      <th>MeanF_Gamma_O2</th>\n",
              "      <th>Spectral Edge_Gamma_O2</th>\n",
              "      <th>PeakF_Gamma_O2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NREM</td>\n",
              "      <td>0.00034</td>\n",
              "      <td>10.11512</td>\n",
              "      <td>17.85756</td>\n",
              "      <td>17.48293</td>\n",
              "      <td>10.24000</td>\n",
              "      <td>0.00047</td>\n",
              "      <td>17.73268</td>\n",
              "      <td>25.35024</td>\n",
              "      <td>27.47317</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00112</td>\n",
              "      <td>0.74927</td>\n",
              "      <td>6.36878</td>\n",
              "      <td>2.87220</td>\n",
              "      <td>0.62439</td>\n",
              "      <td>0.000076</td>\n",
              "      <td>32.71805</td>\n",
              "      <td>43.83220</td>\n",
              "      <td>49.95122</td>\n",
              "      <td>49.95122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NREM</td>\n",
              "      <td>0.00035</td>\n",
              "      <td>10.73951</td>\n",
              "      <td>17.60780</td>\n",
              "      <td>17.10829</td>\n",
              "      <td>9.11610</td>\n",
              "      <td>0.00048</td>\n",
              "      <td>16.85854</td>\n",
              "      <td>25.22537</td>\n",
              "      <td>26.97366</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00070</td>\n",
              "      <td>0.99902</td>\n",
              "      <td>6.86829</td>\n",
              "      <td>3.62146</td>\n",
              "      <td>0.74927</td>\n",
              "      <td>0.000072</td>\n",
              "      <td>32.09366</td>\n",
              "      <td>44.33171</td>\n",
              "      <td>49.95122</td>\n",
              "      <td>49.95122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NREM</td>\n",
              "      <td>0.00035</td>\n",
              "      <td>9.36585</td>\n",
              "      <td>17.60780</td>\n",
              "      <td>16.98341</td>\n",
              "      <td>9.24098</td>\n",
              "      <td>0.00042</td>\n",
              "      <td>17.35805</td>\n",
              "      <td>26.09951</td>\n",
              "      <td>28.47220</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00077</td>\n",
              "      <td>1.49854</td>\n",
              "      <td>6.49366</td>\n",
              "      <td>4.12098</td>\n",
              "      <td>0.74927</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>33.09268</td>\n",
              "      <td>43.95707</td>\n",
              "      <td>49.95122</td>\n",
              "      <td>49.95122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NREM</td>\n",
              "      <td>0.00050</td>\n",
              "      <td>10.36488</td>\n",
              "      <td>16.60878</td>\n",
              "      <td>15.85951</td>\n",
              "      <td>7.99220</td>\n",
              "      <td>0.00053</td>\n",
              "      <td>15.48488</td>\n",
              "      <td>24.10146</td>\n",
              "      <td>25.72488</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00130</td>\n",
              "      <td>1.87317</td>\n",
              "      <td>6.11902</td>\n",
              "      <td>3.74634</td>\n",
              "      <td>0.37463</td>\n",
              "      <td>0.000070</td>\n",
              "      <td>31.59415</td>\n",
              "      <td>42.83317</td>\n",
              "      <td>49.95122</td>\n",
              "      <td>49.95122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NREM</td>\n",
              "      <td>0.00072</td>\n",
              "      <td>9.36585</td>\n",
              "      <td>15.98439</td>\n",
              "      <td>15.48488</td>\n",
              "      <td>7.99220</td>\n",
              "      <td>0.00067</td>\n",
              "      <td>15.11024</td>\n",
              "      <td>22.22829</td>\n",
              "      <td>23.22732</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00123</td>\n",
              "      <td>1.49854</td>\n",
              "      <td>6.61854</td>\n",
              "      <td>3.74634</td>\n",
              "      <td>0.74927</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>29.47122</td>\n",
              "      <td>45.08098</td>\n",
              "      <td>49.95122</td>\n",
              "      <td>49.95122</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 76 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f09497fc-aade-4282-92df-9dc6d87ad8d7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f09497fc-aade-4282-92df-9dc6d87ad8d7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f09497fc-aade-4282-92df-9dc6d87ad8d7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set(list(dataset[target]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS4iUbnyYaDH",
        "outputId": "eb688342-7da0-4374-9c89-1c33c06b194e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'NREM', 'REM'}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder=LabelEncoder()\n",
        "dataset[target]=encoder.fit_transform(dataset[target])"
      ],
      "metadata": {
        "id": "Ljyj9yuIf-tX"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set(list(dataset[target]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42si00q3SLh5",
        "outputId": "e96d4035-3c1e-44bd-f3f5-a50aa5d3a1e0"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rWDFOacMPLpd"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Selection"
      ],
      "metadata": {
        "id": "yxU3_uTmPNdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_ = dataset.loc[:, dataset.columns!=target]\n",
        "y_ = dataset[target]"
      ],
      "metadata": {
        "id": "qLOjEw-uPWuR"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Feature Selection (User Defined with Index Range)"
      ],
      "metadata": {
        "id": "FBLG5DCEWqcm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   Index- [245]  to  [274] -> EEG Features\n",
        "*   Index- [4]    to  [243] -> Normal Features\n",
        "\n"
      ],
      "metadata": {
        "id": "xHRiRL0dY_zS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def FS_UD_index(dataset):\n",
        "  list_of_feat=[]\n",
        "  norm_start=int(input(\"Normal Features Start Index:\"))\n",
        "  norm_end=int(input(\"Normal Features End Index:\"))\n",
        "  eeg_start=int(input(\"EEG Features Start Index:\"))\n",
        "  eeg_end=int(input(\"EEG Features End Index:\"))\n",
        "\n",
        "\n",
        "\n",
        "  list_of_feat=list_of_feat+list(dataset.iloc[:0,norm_start:norm_end])+list(dataset.iloc[:0,eeg_start:eeg_end])\n",
        "  return list_of_feat\n"
      ],
      "metadata": {
        "id": "wYwH4fT-WqDN"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Feature Selection (User Defined with Individual Feature)"
      ],
      "metadata": {
        "id": "lEdeidn9cEd0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Please Input 'Subject' colunm name first**"
      ],
      "metadata": {
        "id": "KLkoTSe3fzZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def FS_UD_feat():\n",
        "  list_of_feat=[]\n",
        "  num=int(input(\"Input number of features: \"))\n",
        "\n",
        "  for i in range(num):\n",
        "    print(i+1,\".\")\n",
        "    list_of_feat.append(input(\"Feature Name: \"))\n",
        "  return list_of_feat\n"
      ],
      "metadata": {
        "id": "1iykvLX8cHku"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Feature Selection (Model Free)"
      ],
      "metadata": {
        "id": "UaMqQtc8z1dc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Type-1**"
      ],
      "metadata": {
        "id": "AjBrNIkMTJaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def FS_bestfeatures_1(X_,y_):\n",
        "  from sklearn.feature_selection import SelectKBest\n",
        "  bestfeatures_1 = SelectKBest(k=10)\n",
        "  fit = bestfeatures_1.fit(X_,y_)\n",
        "  dfscores = pd.DataFrame(fit.scores_)\n",
        "  dfcolumns = pd.DataFrame(X_.columns)\n",
        "  featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
        "  featureScores.columns = ['Specs','Score']\n",
        "\n",
        "\n",
        "  number_of_feat=int(input(\"Number Of Best Features: \"))\n",
        "\n",
        "  imp=featureScores.nlargest(number_of_feat,'Score')\n",
        "\n",
        "  print(imp)\n",
        "  list_of_feat=[]\n",
        "\n",
        "  for i in range(number_of_feat):\n",
        "    list_of_feat.append(imp.iloc[:,0:1].values[i][0])\n",
        "\n",
        "\n",
        "  return list_of_feat"
      ],
      "metadata": {
        "id": "PAG90MeI0S7O"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Type-2**"
      ],
      "metadata": {
        "id": "Ftetc2yrTV6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def FS_bestfeatures_2(X_,y_):\n",
        "  from sklearn.feature_selection import SelectKBest,f_classif\n",
        "  bestfeatures_2=SelectKBest(f_classif, k=10)\n",
        "  fit = bestfeatures_2.fit(X_,y_)\n",
        "  dfscores = pd.DataFrame(fit.scores_)\n",
        "  dfcolumns = pd.DataFrame(X_.columns)\n",
        "  featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
        "  featureScores.columns = ['Specs','Score']\n",
        "\n",
        "\n",
        "  number_of_feat=int(input(\"Number Of Best Features: \"))\n",
        "\n",
        "  imp=featureScores.nlargest(number_of_feat,'Score')\n",
        "\n",
        "  print(imp)\n",
        "  list_of_feat=[]\n",
        "\n",
        "  for i in range(number_of_feat):\n",
        "    list_of_feat.append(imp.iloc[:,0:1].values[i][0])\n",
        "\n",
        "  return list_of_feat"
      ],
      "metadata": {
        "id": "2u0_C3phPo4J"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Type-3**"
      ],
      "metadata": {
        "id": "ftYkiPhdTYrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def FS_bestfeatures_3(X_,y_):\n",
        "  from sklearn.feature_selection import SelectFpr, f_classif\n",
        "\n",
        "  bestfeatures_3=SelectFpr(f_classif, alpha=0.1)\n",
        "  fit = bestfeatures_3.fit(X_,y_)\n",
        "  dfscores = pd.DataFrame(fit.scores_)\n",
        "  dfcolumns = pd.DataFrame(X_.columns)\n",
        "  featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
        "  featureScores.columns = ['Specs','Score']\n",
        "\n",
        "  number_of_feat=int(input(\"Number Of Best Features: \"))\n",
        "\n",
        "  imp=featureScores.nlargest(number_of_feat,'Score')\n",
        "  \n",
        "  print(imp)\n",
        "  list_of_feat=[]\n",
        "\n",
        "  for i in range(number_of_feat):\n",
        "    list_of_feat.append(imp.iloc[:,0:1].values[i][0])\n",
        "\n",
        "  return list_of_feat"
      ],
      "metadata": {
        "id": "UCT592TwR7VO"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Feature Selection (Model Based)"
      ],
      "metadata": {
        "id": "TwYIOctDZBnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def FS_model(X_, y_):\n",
        "  number_of_feat=int(input(\"Number Of Best Features: \"))\n",
        "\n",
        "  from sklearn.feature_selection import SequentialFeatureSelector\n",
        "  from sklearn.neighbors import KNeighborsClassifier\n",
        "  knn = KNeighborsClassifier(n_neighbors=3)\n",
        "  sfs = SequentialFeatureSelector(knn, n_features_to_select=number_of_feat)\n",
        "  sfs.fit(X_, y_)\n",
        "  list_of_feat=[]\n",
        "  list_of_feat=list(sfs.get_feature_names_out(list(dataset.iloc[:0,3:])))\n",
        "\n",
        "  return list_of_feat"
      ],
      "metadata": {
        "id": "Bes4X8B7ZIf5"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Combine in a def"
      ],
      "metadata": {
        "id": "wjNu-Wmqar1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Feat_Select(num,dataset,X_,y_):\n",
        "  if num==0:\n",
        "    return list(X_.columns)\n",
        "  if num==1:\n",
        "    return FS_UD_index(dataset)\n",
        "  elif num==2:\n",
        "    return FS_UD_feat()\n",
        "  elif num==3:\n",
        "    return FS_bestfeatures_1(X_,y_)\n",
        "  elif num==4:\n",
        "    return FS_bestfeatures_2(X_,y_)\n",
        "  elif num==5:\n",
        "    return FS_bestfeatures_3(X_,y_)\n",
        "  elif num==6:\n",
        "    return FS_model(X_, y_)"
      ],
      "metadata": {
        "id": "9Xfunb7iaqZH"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Selection Drop Down"
      ],
      "metadata": {
        "id": "PHDzzzurPBeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "key=widgets.Dropdown(\n",
        "    options=[('ALL', 0),('User Defined with Index Range', 1), ('User Defined with Individual Feature', 2),\n",
        "             ('Model Free 1', 3),('Model Free 2',4),('Model Free 3',5),('Model Based:KNN',6)],\n",
        "    value=0,\n",
        "    description='Feture Select:',\n",
        ")\n",
        "display(key)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2476218d89cf48dc90d8c6fe7baba21f",
            "d02a8553413b492aaf02a91d63999296",
            "c065a1509fa641a6bfa19c6dfd3bdc8c"
          ]
        },
        "id": "J50mMNq7PAU-",
        "outputId": "2b6de48d-5adf-42d4-d1f0-5346bc730cfd"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Feture Select:', options=(('ALL', 0), ('User Defined with Index Range', 1), ('User Defin…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2476218d89cf48dc90d8c6fe7baba21f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_feat=Feat_Select(key.value,dataset,X_,y_)"
      ],
      "metadata": {
        "id": "DJ5FxzZuU-5r"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(list_of_feat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDVg9k74BKKa",
        "outputId": "121b0ad2-e699-4de3-b4ac-1e50a64712c3"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Spliting"
      ],
      "metadata": {
        "id": "C0Akgb_na7NU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(*list_of_feat,sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z21RHPOcZQgP",
        "outputId": "6bb6f4dc-ffd8-44da-fd49-eff44aaa2cdc"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MeanP_Alpha_F4\n",
            "MedianF_Alpha_F4\n",
            "MeanF_Alpha_F4\n",
            "Spectral Edge_Alpha_F4\n",
            "PeakF_Alpha_F4\n",
            "MeanP_Beta_F4\n",
            "MedianF_Beta_F4\n",
            "MeanF_Beta_F4\n",
            "Spectral Edge_Beta_F4\n",
            "PeakF_Beta_F4\n",
            "MeanP_Theta_F4\n",
            "MedianF_Theta_F4\n",
            "MeanF_Theta_F4\n",
            "Spectral Edge_Theta_F4\n",
            "PeakF_Theta_F4\n",
            "MeanP_Delta_F4\n",
            "MedianF_Delta_F4\n",
            "MeanF_Delta_F4\n",
            "Spectral Edge_Delta_F4\n",
            "PeakF_Delta_F4\n",
            "MeanP_Gamma_F4\n",
            "MedianF_Gamma_F4\n",
            "MeanF_Gamma_F4\n",
            "Spectral Edge_Gamma_F4\n",
            "PeakF_Gamma_F4\n",
            "MeanP_Alpha_C4\n",
            "MedianF_Alpha_C4\n",
            "MeanF_Alpha_C4\n",
            "Spectral Edge_Alpha_C4\n",
            "PeakF_Alpha_C4\n",
            "MeanP_Beta_C4\n",
            "MedianF_Beta_C4\n",
            "MeanF_Beta_C4\n",
            "Spectral Edge_Beta_C4\n",
            "PeakF_Beta_C4\n",
            "MeanP_Theta_C4\n",
            "MedianF_Theta_C4\n",
            "MeanF_Theta_C4\n",
            "Spectral Edge_Theta_C4\n",
            "PeakF_Theta_C4\n",
            "MeanP_Delta_C4\n",
            "MedianF_Delta_C4\n",
            "MeanF_Delta_C4\n",
            "Spectral Edge_Delta_C4\n",
            "PeakF_Delta_C4\n",
            "MeanP_Gamma_C4\n",
            "MedianF_Gamma_C4\n",
            "MeanF_Gamma_C4\n",
            "Spectral Edge_Gamma_C4\n",
            "PeakF_Gamma_C4\n",
            "MeanP_Alpha_O2\n",
            "MedianF_Alpha_O2\n",
            "MeanF_Alpha_O2\n",
            "Spectral Edge_Alpha_O2\n",
            "PeakF_Alpha_O2\n",
            "MeanP_Beta_O2\n",
            "MedianF_Beta_O2\n",
            "MeanF_Beta_O2\n",
            "Spectral Edge_Beta_O2\n",
            "PeakF_Beta_O2\n",
            "MeanP_Theta_O2\n",
            "MedianF_Theta_O2\n",
            "MeanF_Theta_O2\n",
            "Spectral Edge_Theta_O2\n",
            "PeakF_Theta_O2\n",
            "MeanP_Delta_O2\n",
            "MedianF_Delta_O2\n",
            "MeanF_Delta_O2\n",
            "Spectral Edge_Delta_O2\n",
            "PeakF_Delta_O2\n",
            "MeanP_Gamma_O2\n",
            "MedianF_Gamma_O2\n",
            "MeanF_Gamma_O2\n",
            "Spectral Edge_Gamma_O2\n",
            "PeakF_Gamma_O2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = dataset[list_of_feat]\n",
        "y_new = dataset.iloc[:, 1]\n",
        "\n",
        "print(type(X_new))\n",
        "print(type(y_new))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auO_-EoE4pro",
        "outputId": "afdcc18c-625d-45d3-a8c8-b98df19f8ba5"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.series.Series'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = dataset[list_of_feat]\n",
        "y_new = dataset[target]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size = 0.2, random_state = 0)\n",
        "result={}"
      ],
      "metadata": {
        "id": "MKgy4THrq4v8"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "bqYsoblRogp2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "BydV84Diooxp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ADABOOST"
      ],
      "metadata": {
        "id": "jEe2R0yAoifa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada_defult = AdaBoostClassifier(random_state=0)\n",
        "ada_defult.fit(X_train, y_train)\n",
        "y_pred = ada_defult.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(ada_defult,1,'AdaBoostClassifier')]=accuracy_score(y_test, y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "Bz_yVJaXod8O",
        "outputId": "d7e9de8e-da85-4eed-cac0-ef416c03d6e5"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-338b784157f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mada_defult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mada_defult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mada_defult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;31m# Boosting step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             sample_weight, estimator_weight, estimator_error = self._boost(\n\u001b[0;32m--> 146\u001b[0;31m                 \u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             )\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \"\"\"\n\u001b[1;32m    547\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"SAMME.R\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m         )\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "N=100\n",
        "k_range = range (1,N+1)\n",
        "scores={}\n",
        "scores_list = []\n",
        "for k in k_range:\n",
        "  classifier = AdaBoostClassifier(n_estimators=k,random_state=0)\n",
        "  classifier.fit(X_train, y_train)\n",
        "  y_pred=classifier.predict(X_test)\n",
        "  scores[k] = accuracy_score(y_test,y_pred)\n",
        "  scores_list.append(accuracy_score(y_test,y_pred))\n",
        "  print(str(k)+\"/\"+str(N)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "#plot the relationship between K and the testing accuracy\n",
        "plt.figure(figsize = (25,10))\n",
        "plt.plot(k_range,scores_list)\n",
        "plt.xlabel('Value of n_estimators')\n",
        "plt.ylabel ('Testing Accuracy')\n",
        "\n",
        "\n",
        "\n",
        "print(\"The best n_estimators:\")\n",
        "best_estimator=list(scores.keys())[scores_list.index(max(scores_list))]\n",
        "print(best_estimator)"
      ],
      "metadata": {
        "id": "_3wRG3rxotzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada_best_estimator = AdaBoostClassifier(n_estimators=best_estimator,random_state=0)\n",
        "ada_best_estimator.fit(X_train, y_train)\n",
        "y_pred = ada_best_estimator.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(ada_best_estimator,1,'AdaBoostClassifier')]=accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "ctzoGCmFo0In"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "JQhATacCo1AD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Graddient Boosting"
      ],
      "metadata": {
        "id": "FJybpt_UvCU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "\n",
        "gradBoost_default = GradientBoostingClassifier(random_state=0)\n",
        "gradBoost_default.fit(X_train, y_train)\n",
        "y_pred = gradBoost_default.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(gradBoost_default,2,'GradientBoostingClassifier')]=accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "sgmvc8A_o18j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "N=75\n",
        "k_range = range (1,N+1)\n",
        "scores={}\n",
        "scores_list = []\n",
        "for k in k_range:\n",
        "  classifier = GradientBoostingClassifier(n_estimators=k,random_state=0)\n",
        "  classifier.fit(X_train, y_train)\n",
        "  y_pred=classifier.predict(X_test)\n",
        "  scores[k] = accuracy_score(y_test,y_pred)\n",
        "  scores_list.append(accuracy_score(y_test,y_pred))\n",
        "  print(str(k)+\"/\"+str(N)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize = (25,10))\n",
        "plt.plot(k_range,scores_list)\n",
        "plt.xlabel('Value of n_estimators')\n",
        "plt.ylabel ('Testing Accuracy')\n",
        "\n",
        "\n",
        "\n",
        "print(\"The best n_estimators:\")\n",
        "best_estimator=list(scores.keys())[scores_list.index(max(scores_list))]\n",
        "print(best_estimator)"
      ],
      "metadata": {
        "id": "9brp-qNgo-tX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "N=30\n",
        "k_range = range (1,N+1)\n",
        "scores={}\n",
        "scores_list = []\n",
        "for k in k_range:\n",
        "  classifier = GradientBoostingClassifier(max_depth=k,random_state=0)\n",
        "  classifier.fit(X_train, y_train)\n",
        "  y_pred=classifier.predict(X_test)\n",
        "  scores[k] = accuracy_score(y_test,y_pred)\n",
        "  scores_list.append(accuracy_score(y_test,y_pred))\n",
        "  print(str(k)+\"/\"+str(N)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize = (25,10))\n",
        "plt.plot(k_range,scores_list)\n",
        "plt.xlabel('Value of n_estimators')\n",
        "plt.ylabel ('Testing Accuracy')\n",
        "\n",
        "\n",
        "\n",
        "print(\"The best Depth:\")\n",
        "best_depth=list(scores.keys())[scores_list.index(max(scores_list))]\n",
        "print(best_depth)"
      ],
      "metadata": {
        "id": "JtO5QAkHpDAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gradBoost_estimator = GradientBoostingClassifier(n_estimators=best_estimator,random_state=0)\n",
        "gradBoost_estimator.fit(X_train, y_train)\n",
        "y_pred = gradBoost_estimator.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(gradBoost_estimator,2,'GradientBoostingClassifier')]=accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "EFg4mMYepGXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gradBoost_depth = GradientBoostingClassifier(max_depth=best_depth,random_state=0)\n",
        "gradBoost_depth.fit(X_train, y_train)\n",
        "y_pred = gradBoost_depth.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "\n",
        "result[(gradBoost_depth,2,'GradientBoostingClassifier')]=accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "oS_ycrCQpI09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gradBoost_all = GradientBoostingClassifier(n_estimators=best_estimator,max_depth=best_depth,random_state=0)\n",
        "gradBoost_all.fit(X_train, y_train)\n",
        "y_pred = gradBoost_all.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "\n",
        "result[(gradBoost_all,2,'GradientBoostingClassifier')]=accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "GU8wNje3pJjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ThoTlhc4pRJT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Random Forest"
      ],
      "metadata": {
        "id": "AgMT_U8gvM7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf_default = RandomForestClassifier(random_state=0)\n",
        "rf_default.fit(X_train, y_train)\n",
        "y_pred=rf_default.predict(X_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(rf_default,3,'RandomForestClassifier')]=accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "-4GMunEvtWk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "N=75\n",
        "k_range = range (1,N+1)\n",
        "scores={}\n",
        "scores_list = []\n",
        "for k in k_range:\n",
        "  classifier = RandomForestClassifier(n_estimators=k,random_state=0)\n",
        "  classifier.fit(X_train, y_train)\n",
        "  y_pred=classifier.predict(X_test)\n",
        "  scores[k] = accuracy_score(y_test,y_pred)\n",
        "  scores_list.append(accuracy_score(y_test,y_pred))\n",
        "  print(str(k)+\"/\"+str(N)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize = (25,10))\n",
        "plt.plot(k_range,scores_list)\n",
        "plt.xlabel('Value of n_estimators')\n",
        "plt.ylabel ('Testing Accuracy')\n",
        "\n",
        "\n",
        "\n",
        "print(\"The best n_estimators:\")\n",
        "best_estimator=list(scores.keys())[scores_list.index(max(scores_list))]\n",
        "print(best_estimator)"
      ],
      "metadata": {
        "id": "ve34YgestieE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "N=30\n",
        "k_range = range (1,N+1)\n",
        "scores={}\n",
        "scores_list = []\n",
        "for k in k_range:\n",
        "  classifier = RandomForestClassifier(max_depth=k,random_state=0)\n",
        "  classifier.fit(X_train, y_train)\n",
        "  y_pred=classifier.predict(X_test)\n",
        "  scores[k] = accuracy_score(y_test,y_pred)\n",
        "  scores_list.append(accuracy_score(y_test,y_pred))\n",
        "  print(str(k)+\"/\"+str(N)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize = (25,10))\n",
        "plt.plot(k_range,scores_list)\n",
        "plt.xlabel('Value of n_estimators')\n",
        "plt.ylabel ('Testing Accuracy')\n",
        "\n",
        "\n",
        "\n",
        "print(\"The best Depth:\")\n",
        "best_depth=list(scores.keys())[scores_list.index(max(scores_list))]\n",
        "print(best_depth)"
      ],
      "metadata": {
        "id": "eVfKbSTWtnny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf_estimator = RandomForestClassifier(n_estimators=best_estimator,random_state=0)\n",
        "rf_estimator.fit(X_train, y_train)\n",
        "y_pred=rf_estimator.predict(X_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(rf_estimator,3,'RandomForestClassifier')]=accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "LMUwwEqUt2-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf_depth = RandomForestClassifier(max_depth=best_depth,random_state=0)\n",
        "rf_depth.fit(X_train, y_train)\n",
        "y_pred=rf_depth.predict(X_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(rf_depth,3,'RandomForestClassifier')]=accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "NRybS4-nt_vO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf_all = RandomForestClassifier(n_estimators=best_estimator,max_depth=best_depth,random_state=0)\n",
        "rf_all.fit(X_train, y_train)\n",
        "y_pred=rf_all.predict(X_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(rf_all,3,'RandomForestClassifier')]=accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "G9p0fJyBtrdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "G_DChNuquB92"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#XGB"
      ],
      "metadata": {
        "id": "jRG4cBnKvZU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import xgboost as xgb\n",
        "xgb_deafult = xgb.XGBClassifier(random_state=0)\n",
        "xgb_deafult.fit(X_train,y_train)\n",
        "y_pred = xgb_deafult.predict(X_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(xgb_deafult,4,'xgboost')]=accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "sC1lAZeeuCw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "N=175\n",
        "k_range = range (1,N+1)\n",
        "scores={}\n",
        "scores_list = []\n",
        "for k in k_range:\n",
        "  xgb_classifier = xgb.XGBClassifier(n_estimators=k,random_state=0)\n",
        "  xgb_classifier.fit(X_train, y_train)\n",
        "  y_pred=xgb_classifier.predict(X_test)\n",
        "  scores[k] = accuracy_score(y_test,y_pred)\n",
        "  scores_list.append(accuracy_score(y_test,y_pred))\n",
        "  print(str(k)+\"/\"+str(N)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize = (25,10))\n",
        "plt.plot(k_range,scores_list)\n",
        "plt.xlabel('Value of n_estimators')\n",
        "plt.ylabel ('Testing Accuracy')\n",
        "\n",
        "\n",
        "\n",
        "print(\"The best n_estimators:\")\n",
        "best_estimator=list(scores.keys())[scores_list.index(max(scores_list))]\n",
        "print(best_estimator)"
      ],
      "metadata": {
        "id": "YQYsfVO0uPMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "N=30\n",
        "k_range = range (1,N+1)\n",
        "scores={}\n",
        "scores_list = []\n",
        "for k in k_range:\n",
        "  xgb_classifier = xgb.XGBClassifier(max_depth=k,random_state=0)\n",
        "  xgb_classifier.fit(X_train, y_train)\n",
        "  y_pred=xgb_classifier.predict(X_test)\n",
        "  scores[k] = accuracy_score(y_test,y_pred)\n",
        "  scores_list.append(accuracy_score(y_test,y_pred))\n",
        "  print(str(k)+\"/\"+str(N)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize = (25,10))\n",
        "plt.plot(k_range,scores_list)\n",
        "plt.xlabel('Value of n_estimators')\n",
        "plt.ylabel ('Testing Accuracy')\n",
        "\n",
        "\n",
        "\n",
        "print(\"The best depth:\")\n",
        "best_depth=list(scores.keys())[scores_list.index(max(scores_list))]\n",
        "print(best_depth)"
      ],
      "metadata": {
        "id": "ABex6e-3kxuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "xgb_depth = xgb.XGBClassifier(max_depth=best_depth,random_state=0)\n",
        "xgb_depth.fit(X_train,y_train)\n",
        "y_pred = xgb_depth.predict(X_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(xgb_depth,4,'xgboost')]=accuracy_score(y_test, y_pred)\n",
        "print(xgb_depth)"
      ],
      "metadata": {
        "id": "lfBp-uGXuaKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "xgb_estimator = xgb.XGBClassifier(n_estimators=best_estimator,random_state=0)\n",
        "xgb_estimator.fit(X_train,y_train)\n",
        "y_pred = xgb_estimator.predict(X_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(xgb_estimator,4,'xgboost')]=accuracy_score(y_test, y_pred)\n",
        "print(xgb_estimator)"
      ],
      "metadata": {
        "id": "_qBm-yTqzOsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "xgb_all = xgb.XGBClassifier(n_estimators=best_estimator,max_depth=best_depth,random_state=0)\n",
        "xgb_all.fit(X_train,y_train)\n",
        "y_pred = xgb_all.predict(X_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(xgb_all,4,'xgboost')]=accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "zW-0PfT-zX3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#KNN"
      ],
      "metadata": {
        "id": "K6_icFWdauSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn_default = KNeighborsClassifier()\n",
        "knn_default.fit(X_train, y_train)\n",
        "y_pred=knn_default.predict(X_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(knn_default,5,'KNeighborsClassifier')]=accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "6GALUBYbaz1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "Neighbors=75\n",
        "k_range = range (1,Neighbors+1)\n",
        "scores={}\n",
        "scores_list = []\n",
        "for k in k_range:\n",
        "  knn = KNeighborsClassifier(n_neighbors=k)\n",
        "  knn.fit(X_train, y_train)\n",
        "  y_pred=knn.predict(X_test)\n",
        "  scores[k] = accuracy_score(y_test,y_pred)\n",
        "  scores_list.append(accuracy_score(y_test,y_pred))\n",
        "  print(str(k)+\"/\"+str(Neighbors)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize = (25,10))\n",
        "plt.plot(k_range,scores_list)\n",
        "plt.xlabel('Value of n_estimators')\n",
        "plt.ylabel ('Testing Accuracy')\n",
        "\n",
        "\n",
        "\n",
        "print(\"The best Depth:\")\n",
        "best=list(scores.keys())[scores_list.index(max(scores_list))]\n",
        "print(best)"
      ],
      "metadata": {
        "id": "CpSsmYDHa-VF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn_neighbors = KNeighborsClassifier(n_neighbors=best)\n",
        "knn_neighbors.fit(X_train, y_train)\n",
        "y_pred=knn_neighbors.predict(X_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(knn_neighbors,5,'KNeighborsClassifier')]=accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "MIVJZYV8bCjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NB"
      ],
      "metadata": {
        "id": "_Btki9jRvc1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "nb_deafult = GaussianNB()\n",
        "nb_deafult.fit(X_train, y_train)\n",
        "y_pred = nb_deafult.predict(X_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(nb_deafult,6,'GaussianNB')]=accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "iRmd7ve-ubcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "qqsWPAB3uv72"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ANN"
      ],
      "metadata": {
        "id": "jgr08kP5-hNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Hi_Hr8Xe3q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(250, input_shape=(X_test.shape[1],), activation='relu'), # input laye\n",
        "    keras.layers.Dense(150, activation='sigmoid'),\n",
        "    keras.layers.Dense(75, activation='softmax')                    # output layer\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=200)\n",
        "\n",
        "model.evaluate(X_test, y_test)'''"
      ],
      "metadata": {
        "id": "gfSpx9u4-i3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''y_predicted = model.predict(X_test)\n",
        "y_predicted_labels = [np.argmax(i) for i in y_predicted]\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_predicted_labels))\n",
        "print(classification_report(y_test,y_predicted_labels))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_predicted_labels))'''"
      ],
      "metadata": {
        "id": "oBAHhjDf--9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Result"
      ],
      "metadata": {
        "id": "6FEsxCdvkg2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "models=[]\n",
        "\n",
        "for i in result:\n",
        "  models.append(i[0])\n",
        "  print(i[0],i[1],\" : \",result[i])\n",
        "  print(\"---------------------------------------------------------------\")\n",
        "  print()\n"
      ],
      "metadata": {
        "id": "rx7qCLU14Aim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_list=[]\n",
        "sorted_list = sorted(result, key=result.get,reverse=True)\n",
        "\n",
        "for i in sorted_list:\n",
        "  print(i,\"  : \",result[i])\n",
        "  print(\"-------------------------------------------------------------------------------------------------\")\n",
        "\n",
        "print(sorted_list)\n",
        "\n",
        "\n",
        "flage=[]\n",
        "best_models=[]\n",
        "it=0\n",
        "\n",
        "for i in sorted_list:\n",
        "  if it==4:\n",
        "    break\n",
        "\n",
        "  if i[1] not in flage:\n",
        "    best_models.append((i[0],i[2]))\n",
        "    flage.append(i[1])\n",
        "    it+=1\n"
      ],
      "metadata": {
        "id": "slItYG8uLOFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"best_models:\")\n",
        "for i in best_models:\n",
        "  print(i)\n"
      ],
      "metadata": {
        "id": "SR0XBsJDMi_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(best_models)"
      ],
      "metadata": {
        "id": "VQCaVYKA5acD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing Accuracy For Best 4 Models"
      ],
      "metadata": {
        "id": "znXNx2bgUvtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i in best_models:\n",
        "  print(\"--------------------------------------------------\")\n",
        "  print(i[0])\n",
        "  y_pred=i[0].predict(X_train)\n",
        "  print(confusion_matrix(y_train, y_pred))\n",
        "  print(classification_report(y_train,y_pred))\n",
        "  print(\"Accurecy: \",accuracy_score(y_train, y_pred))"
      ],
      "metadata": {
        "id": "2j9CXuBkUuiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Check Box"
      ],
      "metadata": {
        "id": "yxj7OCKlnfcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def models_check_box(models):\n",
        "  import ipywidgets as widgets\n",
        "  from IPython.display import display\n",
        "  new_keys=[]\n",
        "  for i in models:\n",
        "    i=widgets.Checkbox(\n",
        "      value=False,\n",
        "      description=str(i),\n",
        "      disabled=False,\n",
        "      indent=False\n",
        "      )\n",
        "    display(i)\n",
        "    new_keys.append(i)\n",
        "  return new_keys"
      ],
      "metadata": {
        "id": "WmxLp5H6nebe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SHAP"
      ],
      "metadata": {
        "id": "zxxWSX26jsGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap\n",
        "import shap"
      ],
      "metadata": {
        "id": "YUhJ7dWajur-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def SHAP_EXP(model,graph_feat):\n",
        "  print(\"Models: \",model)\n",
        "\n",
        "  explainer = shap.Explainer(model.predict, X_test)\n",
        "\n",
        "  shap_values1 = explainer(X_test)\n",
        "  features_names=list_of_feat\n",
        "\n",
        "  if 'Subjects' in features_names:\n",
        "    features_names.pop(0)\n",
        "\n",
        "\n",
        "  shap.plots.bar(shap_values1,max_display=graph_feat[\"max_display\"])\n",
        "\n",
        "  print(\"---------------------\")\n",
        "\n",
        "  shap.summary_plot(shap_values1,max_display=graph_feat[\"max_display\"],feature_names=features_names)\n",
        "\n",
        "  print(\"---------------------\")\n",
        "\n",
        "  print(\"Local Explaination\")\n",
        "  shap.plots.waterfall(shap_values1[graph_feat[\"shap_values Index\"]],max_display=graph_feat[\"max_display\"])\n",
        "\n",
        "\n",
        "  print(\"---------------------\")\n",
        "\n",
        "  shap.plots.bar(shap_values1[graph_feat[\"shap_values Index\"]],max_display=graph_feat[\"max_display\"])"
      ],
      "metadata": {
        "id": "POk0kUrdB-Y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_keys_7=models_check_box(models)"
      ],
      "metadata": {
        "id": "V-G5szfQDiz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_feat={\n",
        "    \"max_display\":20,\n",
        "    \"shap_values Index\":2\n",
        "}\n",
        "\n",
        "for i in range(len(new_keys_7)):\n",
        "  if new_keys_7[i].value ==True:\n",
        "    SHAP_EXP(models[i],graph_feat)\n",
        "    print(\"---------------------------------------------------------\")\n",
        "    print(\"---------------------------------------------------------\")\n",
        "    print(\"---------------------------------------------------------\")\n",
        "    print(\"---------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "JeD8HT_iDodb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Confusion Matrix For Training"
      ],
      "metadata": {
        "id": "57cQ8dzJX0Lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_keys_5=models_check_box(models)"
      ],
      "metadata": {
        "id": "tDrF5oTkBcZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range(len(new_keys_5)):\n",
        "  if new_keys_5[i].value ==True:\n",
        "    cm = ConfusionMatrix(models[i], classes=classes)\n",
        "\n",
        "    cm.fit(X_train, y_train)\n",
        "    cm.score(X_train, y_train)\n",
        "    cm.show()\n",
        "    print(\"-------------------------------\")\n",
        "    print(\"-------------------------------\")"
      ],
      "metadata": {
        "id": "jhzRUmq9X4CZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Confusion Matrix For Testing"
      ],
      "metadata": {
        "id": "23z3A3f1ol6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_keys_6=models_check_box(models)"
      ],
      "metadata": {
        "id": "b3tHiraMBr_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from yellowbrick.classifier import ConfusionMatrix\n",
        "\n",
        "\n",
        "for i in range(len(new_keys_6)):\n",
        "  if new_keys_6[i].value ==True:\n",
        "    cm = ConfusionMatrix(models[i], classes=classes)\n",
        "\n",
        "    cm.fit(X_train, y_train)\n",
        "    cm.score(X_test, y_test)\n",
        "    cm.show()"
      ],
      "metadata": {
        "id": "5vsqEYhponhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EwT5yAeqols7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ROC Comparaing Machine Learning Models"
      ],
      "metadata": {
        "id": "bwOJ36hchWiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def ROC(mod,X_t,y_t,graph_feat):\n",
        "  r_probs = [0 for _ in range(len(y_t))]\n",
        "\n",
        "  model_probs = []\n",
        "\n",
        "\n",
        "  for i in mod:\n",
        "    model_probs.append(i.predict_proba(X_t))\n",
        "\n",
        "\n",
        "  model_probs2=[]\n",
        "\n",
        "  for i in model_probs:\n",
        "    model_probs2.append(i[:,1])\n",
        "\n",
        "\n",
        "  from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "  model_auc=[]\n",
        "  r_auc = roc_auc_score(y_t, r_probs)\n",
        "\n",
        "  for i in model_probs2:\n",
        "    model_auc.append(roc_auc_score(y_t,i))\n",
        "\n",
        "\n",
        "  fpr_tpr=[]\n",
        "  r_fpr, r_tpr, _ = roc_curve(y_t, r_probs)\n",
        "\n",
        "  for i in model_probs2:\n",
        "    fpr, tpr, _ = roc_curve(y_t, i)\n",
        "    fpr_tpr.append((fpr,tpr))\n",
        "\n",
        "  import matplotlib.pyplot as plt\n",
        "  plt.plot(r_fpr, r_tpr, linestyle='--', label='Random prediction (AUROC = %0.3f)' % r_auc)\n",
        "\n",
        "  for i in range(len(model_auc)):\n",
        "    plt.plot(fpr_tpr[i][0], fpr_tpr[i][1], marker='.', label=str(mod[i])+' (AUROC = %0.3f)' % model_auc[i])\n",
        "\n",
        "  # Title\n",
        "  plt.title(graph_feat[\"Title\"],fontsize= graph_feat[\"Title Size\"], fontweight=graph_feat[\"Title Fontweight\"])\n",
        "  plt.xlabel('False Positive Rate',fontweight=graph_feat[\"X axis Label Fontweight\"],fontsize=graph_feat[\"X axis Label Font Size\"])\n",
        "  plt.ylabel('True Positive Rate',fontweight=graph_feat[\"Y axis Label Fontweight\"],fontsize=graph_feat[\"Y axis Label Font Size\"])\n",
        "  \n",
        "  plt.legend( \n",
        "           prop = {'size' : graph_feat[\"legend Font Size\"]}, \n",
        "           loc = graph_feat[\"legend Position\"])\n",
        "  \n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(graph_feat[\"Fig Width (inches)\"], graph_feat[\"Fig Height (inches)\"])\n",
        "  fig.savefig(graph_feat[\"Fig Saving Name\"], dpi=graph_feat[\"dpi\"])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "5XCVUOkc23oX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Training ROC***<br>\n",
        "Chosse the Models"
      ],
      "metadata": {
        "id": "zDbik7Nf6vq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_keys_2=models_check_box(models)"
      ],
      "metadata": {
        "id": "Co9nhyU864CC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Change  the given dictionary of graph feature for desire graph."
      ],
      "metadata": {
        "id": "Xz5G8tcr6Ulx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph_feat={\n",
        "    \"Title\" : \"ROC Plot Training\",\n",
        "    \"Title Size\":18,\n",
        "    \"Title Fontweight\":'bold',\n",
        "\n",
        "    \"legend Font Size\": 14,\n",
        "    \"legend Position\": \"lower right\",\n",
        "\n",
        "    \"X axis Label Font Size\":16,\n",
        "    \"X axis Label Fontweight\":'bold',\n",
        "\n",
        "    \"Y axis Label Font Size\":16,\n",
        "    \"Y axis Label Fontweight\":'bold',\n",
        "\n",
        "    \"Fig Height (inches)\":10.8,\n",
        "    \"Fig Width (inches)\":18.8,\n",
        "\n",
        "    \"Fig Saving Name\": \"ROC_training.png\",\n",
        "    \"dpi\":100\n",
        "    \n",
        "\n",
        "}\n",
        "\n",
        "mod=[]\n",
        "for i in range(len(new_keys_2)):\n",
        "  if new_keys_2[i].value ==True:\n",
        "    mod.append(models[i])\n",
        "\n",
        "ROC(mod,X_train,y_train,graph_feat)"
      ],
      "metadata": {
        "id": "6VAJMmn-97p3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "I_zBmlgG9x-q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Testing ROC***<br>\n",
        "Chosse the Models"
      ],
      "metadata": {
        "id": "fGFXoWwH9SX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_keys_3=models_check_box(models)"
      ],
      "metadata": {
        "id": "XuGVSd3M9hEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Change  the given dictionary of graph feature for desire graph."
      ],
      "metadata": {
        "id": "whZYw0Q-9gke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph_feat={\n",
        "    \"Title\" : \"ROC Plot Testing\",\n",
        "    \"Title Size\":18,\n",
        "    \"Title Fontweight\":'bold',\n",
        "\n",
        "    \"legend Font Size\": 14,\n",
        "    \"legend Position\": \"lower right\",\n",
        "\n",
        "    \"X axis Label Font Size\":16,\n",
        "    \"X axis Label Fontweight\":'bold',\n",
        "\n",
        "    \"Y axis Label Font Size\":16,\n",
        "    \"Y axis Label Fontweight\":'bold',\n",
        "\n",
        "    \"Fig Height (inches)\":10.8,\n",
        "    \"Fig Width (inches)\":18.8,\n",
        "\n",
        "    \"Fig Saving Name\": \"ROC_testing.png\",\n",
        "    \"dpi\":100\n",
        "\n",
        "}\n",
        "\n",
        "mod=[]\n",
        "for i in range(len(new_keys_3)):\n",
        "  if new_keys_3[i].value ==True:\n",
        "    mod.append(models[i])\n",
        "\n",
        "ROC(mod,X_test,y_test,graph_feat)"
      ],
      "metadata": {
        "id": "hsYH7Q6fkbSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cross_val_score \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XtgWbvJsEwMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "k=5\n",
        "for i in result:\n",
        "  print(i[0],\" -> Accuracy: \",result[i])\n",
        "  l=list(cross_val_score(i[0],X_new.iloc[:,1:], y_new,cv=k))\n",
        "  avg=sum(l)/k\n",
        "  print(i[0],\" -> AVG Accurecy After CV: \"+str(avg)+ \" (For \"+str(k)+\" Fold)\")\n",
        "  print(\"--------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "3unb_F6vE39m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CV ROC"
      ],
      "metadata": {
        "id": "leQ5F46f_SqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def CV_ROC(model,folds,graph_feat):\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  from sklearn import svm\n",
        "  from sklearn.metrics import auc,roc_curve\n",
        "  from sklearn.metrics import RocCurveDisplay\n",
        "  from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "\n",
        "  cv = StratifiedKFold(n_splits=folds)\n",
        "\n",
        "\n",
        "\n",
        "  tprs = []\n",
        "  aucs = []\n",
        "  mean_fpr = np.linspace(0,1,100)\n",
        "  i = 1\n",
        "  for train,test in cv.split(X_new.iloc[:,1:], y_new.values):\n",
        "      prediction = model.fit(X_new.iloc[:,1:].values[train], y_new.values[train]).predict_proba(X_new.iloc[:,1:].values[test])\n",
        "      fpr, tpr, t = roc_curve(y_new.values[test], prediction[:, 1])\n",
        "      tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
        "      roc_auc = auc(fpr, tpr)\n",
        "      aucs.append(roc_auc)\n",
        "      plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
        "      i= i+1\n",
        "\n",
        "  plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
        "  mean_tpr = np.mean(tprs, axis=0)\n",
        "  mean_auc = auc(mean_fpr, mean_tpr)\n",
        "  plt.plot(mean_fpr, mean_tpr, color='blue',\n",
        "          label=r'Mean ROC (AUC = %0.2f )' % (mean_auc),lw=2, alpha=1)\n",
        "\n",
        "  plt.title('CV-ROC-> '+str(model),fontsize= graph_feat[\"Title Size\"], fontweight=graph_feat[\"Title Fontweight\"])\n",
        "  plt.xlabel('False Positive Rate',fontweight=graph_feat[\"X axis Label Fontweight\"],fontsize=graph_feat[\"X axis Label Font Size\"])\n",
        "  plt.ylabel('True Positive Rate',fontweight=graph_feat[\"Y axis Label Fontweight\"],fontsize=graph_feat[\"Y axis Label Font Size\"])\n",
        "  plt.legend( \n",
        "           prop = {'size' : graph_feat[\"legend Font Size\"]}, \n",
        "           loc = graph_feat[\"legend Position\"])\n",
        "  \n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(graph_feat[\"Fig Width (inches)\"], graph_feat[\"Fig Height (inches)\"])\n",
        "  fig.savefig(graph_feat[\"Fig Saving Name\"], dpi=graph_feat[\"dpi\"])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "nndrB1Q18Ele"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_keys=models_check_box(models)"
      ],
      "metadata": {
        "id": "kV7r1qnm4G9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run this cell after selecting\n",
        "\n",
        "graph_feat={\n",
        "    \"Title Size\":18,\n",
        "    \"Title Fontweight\":'bold',\n",
        "\n",
        "    \"legend Font Size\": 14,\n",
        "    \"legend Position\": \"lower right\",\n",
        "\n",
        "    \"X axis Label Font Size\":16,\n",
        "    \"X axis Label Fontweight\":'bold',\n",
        "\n",
        "    \"Y axis Label Font Size\":16,\n",
        "    \"Y axis Label Fontweight\":'bold',\n",
        "\n",
        "    \"Fig Height (inches)\":10.8,\n",
        "    \"Fig Width (inches)\":18.8,\n",
        "\n",
        "    \"Fig Saving Name\": \"ROC_testing.png\",\n",
        "    \"dpi\":100\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "k_fold=5\n",
        "\n",
        "for i in range(len(new_keys)):\n",
        "  if new_keys[i].value ==True:\n",
        "    CV_ROC(models[i],5,graph_feat)\n",
        "    print(\"-----------------------------------------------------------------\")\n",
        "    print(\"-----------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "c7Mwtfbj6aPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sm1rGioVdwNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Result CSV<br>\n",
        "Predicted and Actual Row will be added at the end index"
      ],
      "metadata": {
        "id": "Wvhy6ENJf_oS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reverse_transfrom(my_list):\n",
        "  for i in range(len(my_list)):\n",
        "    if my_list[i] == 0:\n",
        "      my_list[i] = 'Control'\n",
        "    else:\n",
        "      my_list[i] = 'Patient'\n",
        "  return my_list"
      ],
      "metadata": {
        "id": "FA_xBniSgLzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_keys_4=models_check_box(models)"
      ],
      "metadata": {
        "id": "iZye8IXAAN9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(new_keys_4)):\n",
        "  if new_keys_4[i].value ==True:\n",
        "    temp=X_test_with_subject\n",
        "\n",
        "    prediction_cls = reverse_transfrom(list(models[i].predict(X_test[0:])))\n",
        "    actual_cls = reverse_transfrom(list(y_test[0:]))\n",
        "\n",
        "    temp[\"Actual\"] = actual_cls\n",
        "    temp[\"Predicted\"] = prediction_cls\n",
        "\n",
        "    temp.to_csv(str(models[i])+\".csv\")"
      ],
      "metadata": {
        "id": "aGw3UapChSZE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}